
R version 4.3.2 (2023-10-31) -- "Eye Holes"
Copyright (C) 2023 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ####### Load Libraries #######
> #install.packages('tidyverse')
> library(tidyverse)
── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ dplyr     1.1.3     ✔ readr     2.1.4
✔ forcats   1.0.0     ✔ stringr   1.5.0
✔ ggplot2   3.4.4     ✔ tibble    3.2.1
✔ lubridate 1.9.3     ✔ tidyr     1.3.0
✔ purrr     1.0.2     
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors
> #install.packages('tidymodels')
> library(tidymodels)
── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──
✔ broom        1.0.5     ✔ rsample      1.2.0
✔ dials        1.2.0     ✔ tune         1.1.2
✔ infer        1.0.5     ✔ workflows    1.1.3
✔ modeldata    1.2.0     ✔ workflowsets 1.0.1
✔ parsnip      1.1.1     ✔ yardstick    1.2.0
✔ recipes      1.0.8     
── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──
✖ scales::discard() masks purrr::discard()
✖ dplyr::filter()   masks stats::filter()
✖ recipes::fixed()  masks stringr::fixed()
✖ dplyr::lag()      masks stats::lag()
✖ yardstick::spec() masks readr::spec()
✖ recipes::step()   masks stats::step()
• Search for functions across packages at https://www.tidymodels.org/find/
> #install.packages('DataExplorer')
> #install.packages("poissonreg")
> # library(poissonreg)
> #install.packages("glmnet")
> library(glmnet)
Loading required package: Matrix

Attaching package: ‘Matrix’

The following objects are masked from ‘package:tidyr’:

    expand, pack, unpack

Loaded glmnet 4.1-8
> #library(patchwork)
> # install.packages("rpart")
> #install.packages('ranger')
> library(ranger)
> #install.packages('stacks')
> library(stacks)
> #install.packages('vroom')
> library(vroom)

Attaching package: ‘vroom’

The following object is masked from ‘package:yardstick’:

    spec

The following object is masked from ‘package:scales’:

    col_factor

The following objects are masked from ‘package:readr’:

    as.col_spec, col_character, col_date, col_datetime, col_double,
    col_factor, col_guess, col_integer, col_logical, col_number,
    col_skip, col_time, cols, cols_condense, cols_only, date_names,
    date_names_lang, date_names_langs, default_locale, fwf_cols,
    fwf_empty, fwf_positions, fwf_widths, locale, output_column,
    problems, spec

> #install.packages('parsnip')
> library(parsnip)
> # install.packages('dbarts')
> # library(dbarts)
> #install.packages('embed')
> library(embed)
> library(themis)
> library(ggplot2)
> library(parsnip)
> ##############################
> 
> ###############
> ##### EDA #####
> ###############
> 
> # data_train <- vroom("./data/train.csv")
> # view(data_train)
> # 
> # cor_matrix <- cor(data_train)
> # 
> # # Create corr heatmap
> # heatmap(cor_matrix,
> #         col = colorRampPalette(c('blue', 'white', 'green'))(100),
> #         margins = c(5, 5),
> #         Rowv = NA,
> #         Colv = NA)
> # 
> # cor_vals_foresttype <- cor_matrix[, 'Cover_Type']
> # ordered_indeces <- order(-cor_vals_foresttype)
> # ordered_cor_vals_foresttype <- cor_vals_foresttype[ordered_indeces]
> # ordered_cor_vals_foresttype
> # 
> # boxplot(data_train$Soil_Type10 ~ data_train$Cover_Type,
> #         col='steelblue',
> #         main='Cover type by soil 10',
> #         xlab='Cover Type',
> #         ylab='Soil 10')
> # 
> # boxplot(data_train$Soil_Type29 ~ data_train$Cover_Type,
> #         col='steelblue',
> #         main='Cover type by soil 29',
> #         xlab='Cover Type',
> #         ylab='Soil 29')
> # 
> # boxplot(data_train$Wilderness_Area1 ~ data_train$Cover_Type,
> #         col='steelblue',
> #         main='Cover type by WA 1',
> #         xlab='Cover Type',
> #         ylab='WA 1')
> # 
> # boxplot(data_train$Wilderness_Area3 ~ data_train$Cover_Type,
> #         col='steelblue',
> #         main='Cover type by WA 3',
> #         xlab='Cover Type',
> #         ylab='WA 3')
> # 
> # boxplot(data_train$Hillshade_Noon ~ data_train$Cover_Type,
> #         col='steelblue',
> #         main='Cover type by noon shade',
> #         xlab='Cover Type',
> #         ylab='noon shade')
> # 
> # ##########
> # # multicollinearity EDA
> # ##########
> # data_wild_areas <- data_train %>%
> #   select(c('Wilderness_Area1',
> #            'Wilderness_Area2',
> #            'Wilderness_Area3',
> #            'Wilderness_Area4'))
> # 
> # cor_matrix_wild_areas <- cor(data_wild_areas)
> # 
> # # Create corr heatmap
> # heatmap(cor_matrix_wild_areas,
> #         col = colorRampPalette(c('blue', 'white', 'green'))(100),
> #         margins = c(5, 5),
> #         Rowv = NA,
> #         Colv = NA,
> #         cexRow = 0.6,
> #         cexCol = 0.6)
> 
> 
> #############################################
> ##### Find value frequencies of factors #####
> #############################################
> 
> # data_train['Id']
> # 
> # column_unique_df <- data.frame(column_name = character(0), frequency = list())
> # # column_unique_df$frequency <- NA
> # 
> # for(column in colnames(data_train)){
> #     unique_vals <- table(data_train[[column]])
> #     sorted_vals <- sort(unique_vals, decreasing = TRUE)
> #     second_largest <- as.numeric(sorted_vals[2])[1]
> #     
> #     new_row <- data.frame(column_name = column, frequency = second_largest)
> #     
> #     colnames(new_row) <- colnames(column_unique_df)
> #     
> #     column_unique_df <- rbind(column_unique_df, new_row)
> #     
> # }
> # 
> # colnames(column_unique_df) <- c('column_name', 'second_freq')
> # view(column_unique_df)
> # 
> # sort(table(data_train[['Horizontal_Distance_To_Roadways']]), decreasing = TRUE)
> 
> #######################
> ##### Recipe/Bake #####
> #######################
> 
> # Import Dataset:
> data_train <- vroom("./data/train.csv") %>%
+   mutate(Cover_Type=factor(Cover_Type))# grab training data
Rows: 15120 Columns: 56
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
dbl (56): Id, Elevation, Aspect, Slope, Horizontal_Distance_To_Hydrology, Ve...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
> 
> ncol(data_train)
[1] 56
> # view(data_train)
> # data_train$Cover_Type
> 
> 
> rFormula <- Cover_Type ~ .
> 
> ## For target encoding/Random Forests: ###
> class_rf_recipe <- recipe(rFormula, data = data_train) %>% # set model formula and dataset
+   step_mutate_at(c(12:55), fn = factor) %>%
+   #step_other(all_nominal_predictors(), threshold = .001) %>%
+   step_mutate(distance = sqrt((Vertical_Distance_To_Hydrology)^2) + (Horizontal_Distance_To_Hydrology)^2) %>%
+   step_select(-Vertical_Distance_To_Hydrology, - Horizontal_Distance_To_Hydrology) %>%
+   step_zv(all_predictors()) %>% # eliminate zero variance predictors
+   step_nzv(freq_cut = 15070/50) %>%
+   step_lencode_glm(all_nominal_predictors(), outcome = vars(Cover_Type)) %>%
+   step_pca(all_predictors(), threshold = 0.8) #%>% # Threshold between 0 and 1, test run for classification rf
> # step_smote(all_outcomes(), neighbors = 5)
> 
> prepped_recipe <- prep(class_rf_recipe) # preprocessing new data
> baked_data1 <- bake(prepped_recipe, new_data = data_train)
> 
> 
> ########################################
> ##### Classification Random Forest #####
> ########################################
> 
> ########## The following should be uncommented for SMOTE ##############
> 
> class_rf_mod <- rand_forest(mtry = tune(),
+                             min_n = tune(),
+                             trees = 1000) %>% #Type of model
+   set_engine('ranger') %>%
+   set_mode('classification')
> 
> pretune_workflow <- workflow() %>%
+   add_recipe(class_rf_recipe) %>%
+   add_model(class_rf_mod)
> 
> ## Grid of values to tune over
> tuning_grid <- grid_regular(mtry(range = c(2,ncol(data_train)-1)),
+                             min_n(),
+                             levels = 3) ## L^2 total tuning possibilities
> 
> # Split data for CV
> folds <- vfold_cv(data_train, v = 5, repeats = 1)
> 
> # Run CV
> CV_results <- pretune_workflow %>%
+   tune_grid(resamples = folds,
+             grid = tuning_grid,
+             metrics = metric_set(roc_auc))
→ A | warning: 2 columns were requested but there were 1 predictors in the data. 1 will be used.
There were issues with some computations   A: x1
→ B | warning: 28 columns were requested but there were 1 predictors in the data. 1 will be used.
There were issues with some computations   A: x1There were issues with some computations   A: x1   B: x1
→ C | warning: 55 columns were requested but there were 1 predictors in the data. 1 will be used.
There were issues with some computations   A: x1   B: x1There were issues with some computations   A: x1   B: x1   C: x1
There were issues with some computations   A: x2   B: x1   C: x1
There were issues with some computations   A: x2   B: x2   C: x1
There were issues with some computations   A: x2   B: x2   C: x2
There were issues with some computations   A: x3   B: x2   C: x2
There were issues with some computations   A: x3   B: x3   C: x2
There were issues with some computations   A: x3   B: x3   C: x3
There were issues with some computations   A: x4   B: x3   C: x3
There were issues with some computations   A: x4   B: x4   C: x3
There were issues with some computations   A: x4   B: x4   C: x4
There were issues with some computations   A: x5   B: x4   C: x4
There were issues with some computations   A: x5   B: x5   C: x4
There were issues with some computations   A: x5   B: x5   C: x5
There were issues with some computations   A: x6   B: x5   C: x5
There were issues with some computations   A: x6   B: x6   C: x5
There were issues with some computations   A: x6   B: x6   C: x6
There were issues with some computations   A: x7   B: x6   C: x6
There were issues with some computations   A: x7   B: x7   C: x6
There were issues with some computations   A: x7   B: x7   C: x7
There were issues with some computations   A: x8   B: x7   C: x7
There were issues with some computations   A: x8   B: x8   C: x7
There were issues with some computations   A: x8   B: x8   C: x8
There were issues with some computations   A: x9   B: x8   C: x8
There were issues with some computations   A: x9   B: x9   C: x8
There were issues with some computations   A: x9   B: x9   C: x9
There were issues with some computations   A: x10   B: x9   C: x9
There were issues with some computations   A: x10   B: x10   C: x9
There were issues with some computations   A: x10   B: x10   C: x10
There were issues with some computations   A: x11   B: x10   C: x10
There were issues with some computations   A: x11   B: x11   C: x10
There were issues with some computations   A: x11   B: x11   C: x11
There were issues with some computations   A: x12   B: x11   C: x11
There were issues with some computations   A: x12   B: x12   C: x11
There were issues with some computations   A: x12   B: x12   C: x12
There were issues with some computations   A: x13   B: x12   C: x12
There were issues with some computations   A: x13   B: x13   C: x12
There were issues with some computations   A: x13   B: x13   C: x13
There were issues with some computations   A: x14   B: x13   C: x13
There were issues with some computations   A: x14   B: x14   C: x13
There were issues with some computations   A: x14   B: x14   C: x14
There were issues with some computations   A: x15   B: x14   C: x14
There were issues with some computations   A: x15   B: x15   C: x14
There were issues with some computations   A: x15   B: x15   C: x15
There were issues with some computations   A: x15   B: x15   C: x15

> 
> bestTune <- CV_results %>%
+   select_best('roc_auc')
> 
> final_wf <- pretune_workflow %>%
+   finalize_workflow(bestTune) %>%
+   fit(data = data_train)
Warning message:
2 columns were requested but there were 1 predictors in the data. 1 will be used. 
> 
> data_test <- vroom("./data/test.csv") # grab testing data
Rows: 565892 Columns: 55
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
dbl (55): Id, Elevation, Aspect, Slope, Horizontal_Distance_To_Hydrology, Ve...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
> 
> fct_predictions <- predict(final_wf,
+                            new_data=data_test,
+                            type="class") %>% # "class" or "prob"
+   mutate(Id = data_test$Id) %>%
+   #mutate(ACTION = ifelse(.pred_1 > .95, 1, 0)) %>%
+   mutate(Cover_Type = .pred_class) %>%
+   select(Id, Cover_Type)
Error in `step_select()`:
! The following required column is missing from `new_data` in step
  'select_BYBNJ': Cover_Type.
Backtrace:
     ▆
  1. ├─... %>% select(Id, Cover_Type)
  2. ├─dplyr::select(., Id, Cover_Type)
  3. ├─dplyr::mutate(., Cover_Type = .pred_class)
  4. ├─dplyr::mutate(., Id = data_test$Id)
  5. ├─stats::predict(final_wf, new_data = data_test, type = "class")
  6. └─workflows:::predict.workflow(...)
  7.   └─workflows:::forge_predictors(new_data, workflow)
  8.     ├─hardhat::forge(new_data, blueprint = mold$blueprint)
  9.     └─hardhat:::forge.data.frame(new_data, blueprint = mold$blueprint)
 10.       ├─hardhat::run_forge(blueprint, new_data = new_data, outcomes = outcomes)
 11.       └─hardhat:::run_forge.default_recipe_blueprint(...)
 12.         └─hardhat:::forge_recipe_default_process(...)
 13.           ├─recipes::bake(object = rec, new_data = new_data)
 14.           └─recipes:::bake.recipe(object = rec, new_data = new_data)
 15.             ├─recipes::bake(step, new_data = new_data)
 16.             └─recipes:::bake.step_select(step, new_data = new_data)
 17.               └─recipes::check_new_data(object$terms, object, new_data)
 18.                 └─cli::cli_abort(...)
 19.                   └─rlang::abort(...)
Execution halted
