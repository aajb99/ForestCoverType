beta_b <- 0.005
#collect data
y1 <- c(0.0952, 0.0627, 0.0702, 0.0930, 0.0526, 0.0521, 0.1066, 0.0436, 0.0339, 0.1070)
y2 <- c(0.0466, 0.0475, 0.0875, 0.0593, 0.0347, 0.0474, 0.0379, 0.0741, 0.1070, 0.0628)
hist(y1)
hist(y2)
#MCMC setup
#number of iterations
iters <- 10000
#create vectors to save sampled values
alpha.save <- beta.save <- rep(0, iters)
#starting values
alpha.start <- 2
beta.start <- 5
#tuning parameters
s.alpha <- .1
s.beta <- 5
#acceptance trackers
accept.alpha <- accept.beta <- 0
# MCMC
for(i in 1:iters){
#sample a value of mu from its full conditional (using Metropolis RW)
alpha.star <- rnorm(1, alpha.start, s.alpha)
#no constraints on mu
logr <- sum(dbeta(y1, alpha.star, beta.start, log = T)) + dgamma(alpha.star, alpha_a, beta_a, log=T) - # likelihood taking our current alpha ratioed by our starting alpha (new/old)
sum(dbeta(y1, alpha.start, beta.start, log = T)) - dgamma(alpha.start, alpha_a, beta_a, log=T)
logu <- log(runif(1))
#print(paste("alpha.start:", alpha.start))
if(logu <= logr){
alpha.start <- alpha.star
accept.alpha <- accept.alpha + 1
}
alpha.save[i] <- alpha.start #save the new current value of alpha
#draw a value of beta from its full conditional distribution (using Metropolis RW)
beta.star <- rnorm(1, beta.start, s.beta)
if(beta.star > 0){ #beta must be > 0
logr <- sum(dbeta(y1, alpha.start, beta.star, log = T)) + dgamma(beta.star, alpha_a, beta_a, log=T) -
sum(dbeta(y1, alpha.start, beta.start, log = T)) - dgamma(beta.start, alpha_a, beta_a, log=T)
logu <- log(runif(1))
if(logu <= logr){
beta.start <- beta.star
accept.beta <- accept.beta + 1
}
}
beta.save[i] <- beta.start #save the new current value of beta
}
#check acceptance rates
accept.alpha/iters
accept.beta/iters
#Look at trace plots
plot(alpha.save, type='l')
plot(beta.save, type='l')
burn <- 1000
alpha1.use <- alpha.save[-(1:burn)]
beta1.use <- beta.save[-(1:burn)]
plot(alpha1.use, beta1.use) #are these parameters correlated a posteriori?
# posterior distributions of means
# calculate the means
mean1 <- alpha1.use / (alpha1.use + beta1.use)
mean2 <- alpha2.use / (alpha2.use + beta2.use)
#plot
plot(density(alpha1.use), xlab=expression(mu_1), ylab="density", main=expression(pi(mu_1~"|"~data)), lwd=2)
lines(density(mean2), col='gray', lwd=2)
legend("topleft", c("Mean 1", "Mean 2"), col=c("black", "gray"), lty=1, lwd=2)
# posterior distributions of means
# calculate the means
mean1 <- alpha1.use / (alpha1.use + beta1.use)
mean2 <- alpha2.use / (alpha2.use + beta2.use)
mean2
#plot
plot(density(alpha1.use), xlab=expression(mu_1), ylab="density", main=expression(pi(mu_1~"|"~data)), lwd=2)
lines(density(mean2), col='gray', lwd=2)
legend("topleft", c("Mean 1", "Mean 2"), col=c("black", "gray"), lty=1, lwd=2)
# posterior distributions of means
# calculate the means
mean1 <- alpha1.use / (alpha1.use + beta1.use)
mean2 <- alpha2.use / (alpha2.use + beta2.use)
#plot
plot(density(mean1), xlab=expression(mu_1), ylab="density", main=expression(pi(mu_1~"|"~data)), lwd=2)
lines(density(mean2), col='gray', lwd=2)
legend("topleft", c("Mean 1", "Mean 2"), col=c("black", "gray"), lty=1, lwd=2)
?yscale()
# posterior distributions of means
# calculate the means
mean1 <- alpha1.use / (alpha1.use + beta1.use)
mean2 <- alpha2.use / (alpha2.use + beta2.use)
#plot
plot(density(mean1), xlab=expression(mu_1), ylab="density", main=expression(pi(mu_1~"|"~data)), lwd=2, ylim = c(0, 50))
lines(density(mean2), col='gray', lwd=2)
legend("topleft", c("Mean 1", "Mean 2"), col=c("black", "gray"), lty=1, lwd=2)
# posterior distributions of means
# calculate the means
mean1 <- alpha1.use / (alpha1.use + beta1.use)
mean2 <- alpha2.use / (alpha2.use + beta2.use)
#plot
plot(density(mean1), xlab=expression(mu_1), ylab="density", main=expression(pi(mu_1~"|"~data)), lwd=2, ylim = c(0, 50))
lines(density(mean2), col='gray', lwd=2
legend("topright", c("Mean 1", "Mean 2"), col=c("black", "gray"), lty=1, lwd=2)
# posterior distributions of means
# calculate the means
mean1 <- alpha1.use / (alpha1.use + beta1.use)
mean2 <- alpha2.use / (alpha2.use + beta2.use)
#plot
plot(density(mean1), xlab=expression(mu_1), ylab="density", main=expression(pi(mu_1~"|"~data)), lwd=2, ylim = c(0, 50))
lines(density(mean2), col='gray', lwd=2)
legend("topright", c("Mean 1", "Mean 2"), col=c("black", "gray"), lty=1, lwd=2)
# posterior distributions of means
# calculate the means
mean1 <- alpha1.use / (alpha1.use + beta1.use)
mean2 <- alpha2.use / (alpha2.use + beta2.use)
#plot
plot(density(mean1), xlab=expression(mu_1), ylab="density", main=expression(pi(mu_1~"|"~data)), lwd=2, ylim = c(0, 47))
lines(density(mean2), col='gray', lwd=2)
legend("topright", c("Mean 1", "Mean 2"), col=c("black", "gray"), lty=1, lwd=2)
# posterior distributions of means
# calculate the means
mean1 <- alpha1.use / (alpha1.use + beta1.use)
mean2 <- alpha2.use / (alpha2.use + beta2.use)
#plot
plot(density(mean1), xlab=expression(mu_1), ylab="density", main=expression(pi(mu_1~"|"~data)), lwd=2, ylim = c(0, 47))
lines(density(mean2), col='gray', lwd=2)
legend("topright", c("Pop Mean 1", "Pop Mean 2"), col=c("black", "gray"), lty=1, lwd=2)
mean(mean1 > mean2)
mean(mean1 < mean2)
mean(mean1 > mean2)
# Posterior predictive:
y1.dot <- rgamma(length(mean1), alpha1.use, beta1.use)
plot(density(y1.dot), lwd=2, main="Posterior Predictive Population 1")
lines(density(y), col=rgb(.4, .6, .4), lwd=2)
# Posterior predictive:
y1.dot <- rgamma(length(mean1), alpha1.use, beta1.use)
plot(density(y1.dot), lwd=2, main="Posterior Predictive Population 1")
# lines(density(y), col=rgb(.4, .6, .4), lwd=2)
legend("topright", legend=c("Post. Pred.", "Data"), lwd=2, col=c("black", rgb(.4, .6, .4)))
#can add a histogram of the data density
#hist(y, freq=F, add=T, col=rgb(.4, .6, .4, .4))
#given our data and prior knowledge, the monthly max
#daily precip will only be above 1 inch
mean(y1.dot>1)
#~14% of the time.
#The 99th percentile (meaning only 1% of the time will monthly max be larger than this)
# is
quantile(y1.dot, .99) #inches
#1 out of every 100 months (more than 8 years)
# will receive a daily max higher than ~1.8inches of precipitation
# Posterior predictive:
y1.dot <- rgamma(length(mean1), alpha1.use, beta1.use)
plot(density(y1.dot), lwd=2, main="Posterior Predictive Population 1")
# lines(density(y), col=rgb(.4, .6, .4), lwd=2)
legend("topright", legend=c("Post. Pred."), lwd=2, col=c("black", rgb(.4, .6, .4)))
#can add a histogram of the data density
#hist(y, freq=F, add=T, col=rgb(.4, .6, .4, .4))
#given our data and prior knowledge, the monthly max
#daily precip will only be above 1 inch
mean(y1.dot>1)
#~14% of the time.
#The 99th percentile (meaning only 1% of the time will monthly max be larger than this)
# is
quantile(y1.dot, .99) #inches
#1 out of every 100 months (more than 8 years)
# will receive a daily max higher than ~1.8inches of precipitation
# Posterior predictive:
y1.dot <- rgamma(length(mean1), alpha1.use, beta1.use)
plot(density(y1.dot), lwd=2, main="Posterior Predictive Population 1")
# lines(density(y), col=rgb(.4, .6, .4), lwd=2)
legend("topright", legend=c("Post. Pred."), lwd=2, col=c("black", rgb(.4, .6, .4)))
#can add a histogram of the data density
#hist(y, freq=F, add=T, col=rgb(.4, .6, .4, .4))
#given our data and prior knowledge, the monthly max
#daily precip will only be above 1 inch
mean(y1.dot>0.5)
#~14% of the time.
#The 99th percentile (meaning only 1% of the time will monthly max be larger than this)
# is
quantile(y1.dot, .99) #inches
#1 out of every 100 months (more than 8 years)
# will receive a daily max higher than ~1.8inches of precipitation
# Posterior predictive:
y1.dot <- rgamma(length(mean1), alpha1.use, beta1.use)
plot(density(y1.dot), lwd=2, main="Posterior Predictive Population 1")
# lines(density(y), col=rgb(.4, .6, .4), lwd=2)
legend("topright", legend=c("Post. Pred."), lwd=2, col=c("black", rgb(.4, .6, .4)))
#can add a histogram of the data density
#hist(y, freq=F, add=T, col=rgb(.4, .6, .4, .4))
#given our data and prior knowledge, the monthly max
#daily precip will only be above 1 inch
mean(y1.dot>0.25)
#~14% of the time.
#The 99th percentile (meaning only 1% of the time will monthly max be larger than this)
# is
quantile(y1.dot, .99) #inches
#1 out of every 100 months (more than 8 years)
# will receive a daily max higher than ~1.8inches of precipitation
# Posterior predictive:
y1.dot <- rgamma(length(mean1), alpha1.use, beta1.use)
plot(density(y1.dot), lwd=2, main="Posterior Predictive Population 1")
# lines(density(y), col=rgb(.4, .6, .4), lwd=2)
legend("topright", legend=c("Post. Pred."), lwd=2, col=c("black", rgb(.4, .6, .4)))
#can add a histogram of the data density
#hist(y, freq=F, add=T, col=rgb(.4, .6, .4, .4))
#given our data and prior knowledge, the monthly max
#daily precip will only be above 1 inch
mean(y1.dot>0.2)
#~0.3% of the time.
# is
quantile(y1.dot, .99) #inches
# Posterior predictive:
y1.dot <- rgamma(length(mean1), alpha1.use, beta1.use)
plot(density(y1.dot), lwd=2, main="Posterior Predictive Population 1")
# lines(density(y), col=rgb(.4, .6, .4), lwd=2)
legend("topright", legend=c("Post. Pred."), lwd=2, col=c("black", rgb(.4, .6, .4)))
#can add a histogram of the data density
#hist(y, freq=F, add=T, col=rgb(.4, .6, .4, .4))
#given our data and prior knowledge, the monthly max
#daily precip will only be above 1 inch
mean(y1.dot>0.2)
#~1.56% of the time.
# is
quantile(y1.dot, .99) #inches
# Posterior predictive:
y2.dot <- rgamma(length(mean2), alpha2.use, beta2.use)
plot(density(y2.dot), lwd=2, main="Posterior Predictive Population 2")
# lines(density(y), col=rgb(.4, .6, .4), lwd=2)
legend("topright", legend=c("Post. Pred."), lwd=2, col=c("black", rgb(.4, .6, .4)))
#can add a histogram of the data density
#hist(y, freq=F, add=T, col=rgb(.4, .6, .4, .4))
#given our data and prior knowledge, the monthly max
#daily precip will only be above 1 inch
mean(y2.dot>0.2)
#~1.56% of the time.
# is
quantile(y2.dot, .99) #inches
# Posterior predictive:
y1.dot <- rgamma(length(mean1), alpha1.use, beta1.use)
plot(density(y1.dot), lwd=2, main="Posterior Predictive Population 1")
# lines(density(y), col=rgb(.4, .6, .4), lwd=2)
legend("topright", legend=c("Post. Pred."), lwd=2, col=c("black", rgb(.4, .6, .4)))
#can add a histogram of the data density
#hist(y, freq=F, add=T, col=rgb(.4, .6, .4, .4))
#given our data and prior knowledge, the monthly max
#daily precip will only be above 1 inch
mean(y1.dot>0.2)
#~1.2% of the time.
# is
quantile(y1.dot, .99) #inches
# Posterior predictive:
y2.dot <- rgamma(length(mean2), alpha2.use, beta2.use)
plot(density(y2.dot), lwd=2, main="Posterior Predictive Population 2")
# lines(density(y), col=rgb(.4, .6, .4), lwd=2)
legend("topright", legend=c("Post. Pred."), lwd=2, col=c("black", rgb(.4, .6, .4)))
#can add a histogram of the data density
#hist(y, freq=F, add=T, col=rgb(.4, .6, .4, .4))
#given our data and prior knowledge, the monthly max
#daily precip will only be above 1 inch
mean(y2.dot>0.2)
#~1.1% of the time.
# is
quantile(y2.dot, .99) #inches
# Posterior predictive:
y1.dot <- rgamma(length(mean1), alpha1.use, beta1.use)
plot(density(y1.dot), lwd=2, main="Posterior Predictive Population 1")
# lines(density(y), col=rgb(.4, .6, .4), lwd=2)
legend("topright", legend=c("Post. Pred."), lwd=2, col=c("black", rgb(.4, .6, .4)))
#can add a histogram of the data density
#hist(y, freq=F, add=T, col=rgb(.4, .6, .4, .4))
#given our data and prior knowledge, the monthly max
#daily precip will only be above 1 inch
mean(y1.dot>0.2)
#~1.2% of the time.
# is
quantile(y1.dot, .99) #inches
# Posterior predictive:
y2.dot <- rgamma(length(mean2), alpha2.use, beta2.use)
plot(density(y2.dot), lwd=2, main="Posterior Predictive Population 2")
# lines(density(y), col=rgb(.4, .6, .4), lwd=2)
legend("topright", legend=c("Post. Pred."), lwd=2, col=c("black", rgb(.4, .6, .4)))
#can add a histogram of the data density
#hist(y, freq=F, add=T, col=rgb(.4, .6, .4, .4))
#given our data and prior knowledge, the monthly max
#daily precip will only be above 1 inch
mean(y2.dot>0.2)
#~1.1% of the time.
# is
quantile(y2.dot, .99) #inches
# Posterior predictive:
y1.dot <- rgamma(length(mean1), alpha1.use, beta1.use)
plot(density(y1.dot), lwd=2, main="Posterior Predictive Population 1")
# lines(density(y), col=rgb(.4, .6, .4), lwd=2)
legend("topright", legend=c("Post. Pred."), lwd=2, col=c("black", rgb(.4, .6, .4)))
#can add a histogram of the data density
#hist(y, freq=F, add=T, col=rgb(.4, .6, .4, .4))
#given our data and prior knowledge, the monthly max
#daily precip will only be above 1 inch
mean(y1.dot>0.2)
#~1.2-1.3% of the time.
# is
quantile(y1.dot, .99) #inches
# Posterior predictive:
y2.dot <- rgamma(length(mean2), alpha2.use, beta2.use)
plot(density(y2.dot), lwd=2, main="Posterior Predictive Population 2")
# lines(density(y), col=rgb(.4, .6, .4), lwd=2)
legend("topright", legend=c("Post. Pred."), lwd=2, col=c("black", rgb(.4, .6, .4)))
#can add a histogram of the data density
#hist(y, freq=F, add=T, col=rgb(.4, .6, .4, .4))
#given our data and prior knowledge, the monthly max
#daily precip will only be above 1 inch
mean(y2.dot>0.2)
#~1.1% of the time.
# is
quantile(y2.dot, .99) #inches
mean(y1.dot > y2.dot)
knitr::opts_chunk$set(echo = TRUE)
library(invgamma)
library(zoo)
#likelihood: Yi|mu, beta iid~ Gumbel(mu, beta) (Note: mu is NOT the mean!)
loglik <- function(yvals, alpha, beta){
ll <- dbeta(yvals, alpha, beta, log = T)
out <- sum(ll) # add log y values of beta dist together
return(ll)
}
#priors (very uninformative -- large uncertainty/variance on both parameters)
alpha_a <- 0.005
beta_a <- 0.005
alpha_b <- 0.005
beta_b <- 0.005
#collect data
y1 <- c(0.0952, 0.0627, 0.0702, 0.0930, 0.0526, 0.0521, 0.1066, 0.0436, 0.0339, 0.1070)
y2 <- c(0.0466, 0.0475, 0.0875, 0.0593, 0.0347, 0.0474, 0.0379, 0.0741, 0.1070, 0.0628)
hist(y1)
hist(y2)
#MCMC setup
#number of iterations
iters <- 10000
#create vectors to save sampled values
alpha.save <- beta.save <- rep(0, iters)
#starting values
alpha.start <- 2
beta.start <- 5
#tuning parameters
s.alpha <- .1
s.beta <- 5
#acceptance trackers
accept.alpha <- accept.beta <- 0
# MCMC
for(i in 1:iters){
#sample a value of mu from its full conditional (using Metropolis RW)
alpha.star <- rnorm(1, alpha.start, s.alpha)
#no constraints on mu
logr <- sum(dbeta(y1, alpha.star, beta.start, log = T)) + dgamma(alpha.star, alpha_a, beta_a, log=T) - # likelihood taking our current alpha ratioed by our starting alpha (new/old)
sum(dbeta(y1, alpha.start, beta.start, log = T)) - dgamma(alpha.start, alpha_a, beta_a, log=T)
logu <- log(runif(1))
#print(paste("alpha.start:", alpha.start))
if(logu <= logr){
alpha.start <- alpha.star
accept.alpha <- accept.alpha + 1
}
alpha.save[i] <- alpha.start #save the new current value of alpha
#draw a value of beta from its full conditional distribution (using Metropolis RW)
beta.star <- rnorm(1, beta.start, s.beta)
if(beta.star > 0){ #beta must be > 0
logr <- sum(dbeta(y1, alpha.start, beta.star, log = T)) + dgamma(beta.star, alpha_a, beta_a, log=T) -
sum(dbeta(y1, alpha.start, beta.start, log = T)) - dgamma(beta.start, alpha_a, beta_a, log=T)
logu <- log(runif(1))
if(logu <= logr){
beta.start <- beta.star
accept.beta <- accept.beta + 1
}
}
beta.save[i] <- beta.start #save the new current value of beta
}
#check acceptance rates
accept.alpha/iters
accept.beta/iters
#Look at trace plots
plot(alpha.save, type='l')
plot(beta.save, type='l')
burn <- 1000
alpha1.use <- alpha.save[-(1:burn)]
beta1.use <- beta.save[-(1:burn)]
plot(alpha1.use, beta1.use) #are these parameters correlated a posteriori?
#likelihood: Yi|mu, beta iid~ Gumbel(mu, beta) (Note: mu is NOT the mean!)
loglik <- function(yvals, alpha, beta){
ll <- dbeta(yvals, alpha, beta, log = T)
out <- sum(ll) # add log y values of beta dist together
return(ll)
}
#priors (very uninformative -- large uncertainty/variance on both parameters)
alpha_a <- 0.005
beta_a <- 0.005
alpha_b <- 0.005
beta_b <- 0.005
hist(y2)
hist(y2)
#MCMC setup
#number of iterations
iters <- 10000
#create vectors to save sampled values
alpha.save <- beta.save <- rep(0, iters)
#starting values
alpha.start <- .1
beta.start <- 5
#tuning parameters
s.alpha <- .05
s.beta <- 2
#acceptance trackers
accept.alpha <- accept.beta <- 0
# MCMC
for(i in 1:iters){
#sample a value of mu from its full conditional (using Metropolis RW)
alpha.star <- rnorm(1, alpha.start, s.alpha)
#no constraints on mu
logr <- sum(dbeta(y2, alpha.star, beta.start, log = T)) + dgamma(alpha.star, alpha_a, beta_a, log=T) - # likelihood taking our current alpha ratioed by our starting alpha (new/old)
sum(dbeta(y2, alpha.start, beta.start, log = T)) - dgamma(alpha.start, alpha_a, beta_a, log=T)
logu <- log(runif(1))
#print(paste("alpha.start:", alpha.start))
if(logu <= logr){
alpha.start <- alpha.star
accept.alpha <- accept.alpha + 1
}
alpha.save[i] <- alpha.start #save the new current value of alpha
#draw a value of beta from its full conditional distribution (using Metropolis RW)
beta.star <- rnorm(1, beta.start, s.beta)
if(beta.star > 0){ #beta must be > 0
logr <- sum(dbeta(y2, alpha.start, beta.star, log = T)) + dgamma(beta.star, alpha_a, beta_a, log=T) -
sum(dbeta(y2, alpha.start, beta.start, log = T)) - dgamma(beta.start, alpha_a, beta_a, log=T)
logu <- log(runif(1))
if(logu <= logr){
beta.start <- beta.star
accept.beta <- accept.beta + 1
}
}
beta.save[i] <- beta.start #save the new current value of beta
}
#check acceptance rates
accept.alpha/iters
accept.beta/iters
#Look at trace plots
plot(alpha.save, type='l')
plot(beta.save, type='l')
burn <- 1000
alpha2.use <- alpha.save[-(1:burn)]
beta2.use <- beta.save[-(1:burn)]
plot(alpha2.use, beta2.use) #are these parameters correlated a posteriori?
knitr::opts_chunk$set(echo = TRUE)
library(invgamma)
library(zoo)
#likelihood: Yi|mu, beta iid~ Gumbel(mu, beta) (Note: mu is NOT the mean!)
loglik <- function(yvals, alpha, beta){
sum(dbeta(yvals, alpha, beta, log = T))
out <- sum(ll) # add log y values of beta dist together
return(ll)
}
#priors (very uninformative -- large uncertainty/variance on both parameters)
alpha_a <- 0.005
beta_a <- 0.005
alpha_b <- 0.005
beta_b <- 0.005
#collect data
y1 <- c(0.0952, 0.0627, 0.0702, 0.0930, 0.0526, 0.0521, 0.1066, 0.0436, 0.0339, 0.1070)
y2 <- c(0.0466, 0.0475, 0.0875, 0.0593, 0.0347, 0.0474, 0.0379, 0.0741, 0.1070, 0.0628)
hist(y1)
hist(y2)
#MCMC setup
#number of iterations
iters <- 10000
#create vectors to save sampled values
alpha.save <- beta.save <- rep(0, iters)
#starting values
alpha.start <- 2
beta.start <- 5
#tuning parameters
s.alpha <- .1
s.beta <- 5
#acceptance trackers
accept.alpha <- accept.beta <- 0
# MCMC
for(i in 1:iters){
#sample a value of mu from its full conditional (using Metropolis RW)
alpha.star <- rnorm(1, alpha.start, s.alpha)
#no constraints on mu
logr <- sum(dbeta(y1, alpha.star, beta.start, log = T)) + dgamma(alpha.star, alpha_a, beta_a, log=T) - # likelihood taking our current alpha ratioed by our starting alpha (new/old)
sum(dbeta(y1, alpha.start, beta.start, log = T)) - dgamma(alpha.start, alpha_a, beta_a, log=T)
logu <- log(runif(1))
#print(paste("alpha.start:", alpha.start))
if(logu <= logr){
alpha.start <- alpha.star
accept.alpha <- accept.alpha + 1
}
alpha.save[i] <- alpha.start #save the new current value of alpha
#draw a value of beta from its full conditional distribution (using Metropolis RW)
beta.star <- rnorm(1, beta.start, s.beta)
if(beta.star > 0){ #beta must be > 0
logr <- sum(dbeta(y1, alpha.start, beta.star, log = T)) + dgamma(beta.star, alpha_a, beta_a, log=T) -
sum(dbeta(y1, alpha.start, beta.start, log = T)) - dgamma(beta.start, alpha_a, beta_a, log=T)
logu <- log(runif(1))
if(logu <= logr){
beta.start <- beta.star
accept.beta <- accept.beta + 1
}
}
beta.save[i] <- beta.start #save the new current value of beta
}
#check acceptance rates
accept.alpha/iters
accept.beta/iters
#Look at trace plots
plot(alpha.save, type='l')
plot(beta.save, type='l')
burn <- 1000
alpha1.use <- alpha.save[-(1:burn)]
beta1.use <- beta.save[-(1:burn)]
plot(alpha1.use, beta1.use) #are these parameters correlated a posteriori?
